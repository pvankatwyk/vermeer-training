{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyN7gQUP9G_1"
   },
   "source": [
    "# Data Engineering Activity\n",
    "This demonstration is to teach data engineering principles that can be applied to a wide range of datasets and data types. In this case, we are working with a synthetic dataset based on drill data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eoAGwVp9ioR"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these cells to load in the approprate packages and make sure the notebook has the data accessible. You should run this on a Jupyter Notebook downloaded earlier in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment if you want full environment setup\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from pandas_profiling import ProfileReport\n",
    "import pickle\n",
    "# import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "try:\n",
    "    from rop_utils import ROPData\n",
    "    data_folder = \"../data/\"\n",
    "except ModuleNotFoundError:\n",
    "    !git clone https://github.com/pvankatwyk/vermeer-training.git\n",
    "    data_folder = \"vermeer-training/data/\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaAcEYpd9oHe"
   },
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the data into Python. The data is currently stored in a Comma Separated Values format (CSV) on your computer's hard drive. In order for python to be able to interface with the data, it will load the data into RAM for easy access and calculation.  \n",
    "\n",
    "Below are a few different file types that python can handle using the Pandas library. For more information on pandas, see the documentation here:  . The same data is loaded from a CSV file, a TXT file, and a XLSX file. Do they look the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuyX-FVgqM8Q",
    "outputId": "cbc85da2-fb56-48bd-e693-ce97e8abb7cc"
   },
   "outputs": [],
   "source": [
    "# Load data from .csv, .txt, and .xlsx files\n",
    "# TODO: Load in the data from both the text file and the csv file (optional, xlsx file also)\n",
    "\n",
    "# Are they the same?\n",
    "# TODO: Write some code to make sure they are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Df0O-Xdfp9nQ",
    "outputId": "783de177-b771-46ac-db76-25bcb4f9c337"
   },
   "outputs": [],
   "source": [
    "# Load in data for this training\n",
    "data = pd.read_csv(data_folder + r'synthetic_drill_data_1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx7cBRZy-UBx"
   },
   "source": [
    "## Step 2: Calculating ROP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for this activity is to learn about and be able to predict the speed of drilling, or Rate of Penetration (ROP). ROP is not a measurement found in the existing data, so we must calculate it and add it to the dataset. We will look at two rows at a time and take the difference in drill depth divided by the difference in timestamps. This will give us a measurement in distance per time (speed), or in our case, feet per minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIdjFNrT-Tg-"
   },
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    # Convert to pandas-recognized timestamp\n",
    "    data['TimeStamp'] = pd.to_datetime(data['TimeStamp'])\n",
    "    n = len(data)\n",
    "    # Create an array for storing the data - \n",
    "    deltaTime = np.zeros(n) * np.nan  # differences in timestamps\n",
    "    forward = [True] * n              # whether the drill is moving forward\n",
    "\n",
    "    # Calculate time stamp differences\n",
    "    for i in range(1, n):\n",
    "        deltaTime[i] = (data['TimeStamp'][i] - data['TimeStamp'][i - 1]).total_seconds()\n",
    "        forward[i] = True if data['RodCount'][i] > data['RodCount'][i - 1] else False\n",
    "\n",
    "    # average of 2 and 3 for 1st time point only\n",
    "    deltaTime[0] = np.mean(deltaTime[1:3])\n",
    "    \n",
    "    # calculate ROP from deltaTime and 10 feet difference between rods\n",
    "    data['ROP (ft/min)'] = (60 * 10.0 / deltaTime)\n",
    "    \n",
    "    # Only include data when the drill is moving forward\n",
    "    data = data[forward]\n",
    "    \n",
    "    # Drop rows with no time change\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def filter(data, column, min=None, max=None):\n",
    "    if max is None:\n",
    "        max = data[column].max()\n",
    "    if min is None:\n",
    "        min = data[column].min()\n",
    "\n",
    "    return data[(data[column] < max) & (data[column] > min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqBkR7LDK0jG"
   },
   "outputs": [],
   "source": [
    "# Process data\n",
    "# TODO: process the data\n",
    "\n",
    "# Filter the data -- ROP > 0\n",
    "# TODO: filter the data\n",
    "#  - Use filter() above\n",
    "filtered_data = \n",
    "\n",
    "data = filtered_data.drop(columns=['Id', 'TimeStamp', 'Latitude', 'Longitude', \"Thrust Speed Avg (ft/min)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLWGsJAXZnfz",
    "outputId": "27c35e0a-389d-44b8-b9df-0e40e325d81e"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGEbA-JLK4kQ"
   },
   "outputs": [],
   "source": [
    "# You can also do this to get the same output...\n",
    "# data = ROPData().upload(data_folder + 'synthetic_drill_data.csv').process().filter(rop_greater_than=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaQAMbYr9tai"
   },
   "source": [
    "## Step 3: Removing Bad Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0j0ibq6d98uI"
   },
   "source": [
    "### Identifying Missing Data  \n",
    "First we need to identify if our dataset has missing fields. The following code sums the number of values that are missing in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdJXSbpX7zRC",
    "outputId": "3fec2b49-5c5e-450a-f865-35a91385d6a3"
   },
   "outputs": [],
   "source": [
    "# TODO: Sum up all the na values in the columns\n",
    "#  - hint: .isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6IWGK-4-AD7"
   },
   "source": [
    "### Handling Missing Data  \n",
    "There are a few different ways of handling missing fields within the data. The best way to deal with missing data is to simply delete the entire row where the field is missing. Since the field is empty, there is no way to know what should go there and we ideally don't want to impose prior knowledge into the data.  \n",
    "\n",
    "However, sometimes the data is not long enough and we cannot afford to delete any of the rows. In that case, you can use imputation, which is a way of filling in the missing field with a logical \"best guess\" such as the column mean, median, or an interpolation between the row before and after. In this exercise, we will simply delete rows with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66Jh5-Vz-aSh"
   },
   "source": [
    "###### Deleting Rows with Missing Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnR42Unb8MjX"
   },
   "outputs": [],
   "source": [
    "# TODO: Drop NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PdmMzdIi8QLT",
    "outputId": "40ef77f4-4b07-4c37-94c0-d0e789eeb36d"
   },
   "outputs": [],
   "source": [
    "# TODO: fill in the same code you wrote above (summing up na values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_vjc5Af-jS8"
   },
   "source": [
    "###### Imputing and Interpolating Missing Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation Example (from [Sklearn Docs](https://scikit-learn.org/stable/modules/impute.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHzxIOvB-jod"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit([[1, 2], [np.nan, 3], [7, 6]])\n",
    "SimpleImputer()\n",
    "X = [[np.nan, 2], [6, np.nan], [7, 6]]\n",
    "print(imp.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation Example (from [SciPy Docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html#scipy.interpolate.interp1d)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "x = np.arange(0, 10)\n",
    "y = np.exp(-x/3.0)\n",
    "f = interpolate.interp1d(x, y)\n",
    "\n",
    "xnew = np.arange(0, 9, 0.1)\n",
    "ynew = f(xnew)   # use interpolation function returned by `interp1d`\n",
    "plt.plot(x, y, 'o', xnew, ynew, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAi7cIp--Fgv"
   },
   "source": [
    "### Identifying Outliers  \n",
    "Now that the data is loaded and missing data is deleted, we need to identify rows that likely are not representative of the true data that we are trying to learn about. This may include faulty measurements due to sensor error, operator error, or simply drillruns that are abnormal. These rows are called outliers.\n",
    "\n",
    "Histograms and boxplots are great ways of looking for outliers. Histograms plot the frequency (count) of data points within a given measurement range. For example, we may see 10 rows that have ROP within 3-4 ft/min. Boxplots are particularly helpful in identifying outliers by using quartiles ranges. For more information on identifying outliers from plots, see this article:  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "yORpBZnktBXo",
    "outputId": "1a6ec7e9-034e-4eea-86fb-8528647430c4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def histograms(columns):\n",
    "    for column in columns:\n",
    "        sns.histplot(data[column])\n",
    "        plt.title(f'Histogram for {column}')\n",
    "        plt.show()\n",
    "        print('')\n",
    "\n",
    "def boxplots(columns):\n",
    "    for column in columns:\n",
    "        sns.boxplot(data[column])\n",
    "        plt.title(f'Boxplot for {column}')\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate quartile ranges\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q2 = data[column].quantile(0.5)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "\n",
    "        # Calculate Inter-Quartile Range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        max_ = Q3 + 1.5*IQR\n",
    "        min_ = Q1 - 1.5*IQR\n",
    "        \n",
    "        min_ = min_ if min_ > 0 else 0\n",
    "\n",
    "        print(f\"{column} -- Median (Q2): {Q2}, Max: {max_}, Min: {min_}\")\n",
    "        print('')\n",
    "\n",
    "columns = ['Rotation Speed Max (rpm)', 'Thrust Force Max (lbf)', 'Drill String Length (ft)', 'ROP (ft/min)']\n",
    "boxplots(columns)\n",
    "histograms(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nmkHgYM-IWQ"
   },
   "source": [
    "### Removing Outliers\n",
    "As you can see from the plots above, there are many outliers in the data that need to be removed. Removing outliers can be very subjective in approach but mathematical principles can be employed to keep the process uniform. We will use the bounds of the boxplots as good boundaries for outlier regions. Below are two functions to help you calculate the data. A typical value for the outlier range is 1.5 (as seen in the boxplot), but we use a value of 2.5 to be inclusive of rows that are extreme but may not be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDmvH7owtX1e"
   },
   "outputs": [],
   "source": [
    "def calculate_bounds(data, outlier_range=1.5):\n",
    "    bounds = {}\n",
    "    for column in data.columns:\n",
    "        try:\n",
    "            Q1 = data[column].quantile(0.25)\n",
    "            Q2 = data[column].quantile(0.5)\n",
    "            Q3 = data[column].quantile(0.75)\n",
    "\n",
    "            IQR = Q3 - Q1\n",
    "            max_ = Q3 + outlier_range*IQR\n",
    "            min_ = Q1 - outlier_range*IQR\n",
    "            \n",
    "            min_ = min_ if min_ > 0 else 0\n",
    "\n",
    "            bounds[column] = {'min_': min_, 'max_': max_}\n",
    "        except TypeError:\n",
    "            pass\n",
    "    return bounds\n",
    "\n",
    "def delete_outliers(data, outlier_range=1.5):\n",
    "    bounds = calculate_bounds(data, outlier_range=outlier_range)\n",
    "    for column in bounds.keys():\n",
    "        data = data[(data[column] <= bounds[column]['max_']) & (data[column] >= bounds[column]['min_'])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NUtbcbzBnc8"
   },
   "outputs": [],
   "source": [
    "data = delete_outliers(data, outlier_range=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "pGV8aLQdz2Nb",
    "outputId": "7d0ce68c-d245-40c1-b28a-cab16e5657f9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplots(columns)\n",
    "histograms(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data now looks much more representative of real values and is ready to be visualized and modeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOBKG5OFTQZe"
   },
   "source": [
    "## Step 4: Visualizing Data\n",
    "\n",
    "Visualization is an important step in understanding the underlying principles governing your data. There are hundreds of different kinds of plots we can use to plot data. Below are a few different functions that will help you plot the data. Try using the functions to plot different columns in the dataset and start thinking about what patterns you see may tell us about the underlying processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhKiqWsKbd8h"
   },
   "source": [
    "#### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5xd8a-LNSmV"
   },
   "outputs": [],
   "source": [
    "def scatterplot(data, x_column, y_column, fits=None):\n",
    "    x = data[x_column]\n",
    "    y = data[y_column]\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(f'{x_column} vs {y_column}')\n",
    "    plt.xlabel(str(x_column))\n",
    "    plt.ylabel(str(y_column))\n",
    "\n",
    "    if fits is None:\n",
    "        return None\n",
    "    \n",
    "    elif \"linear\" in fits.lower():\n",
    "        fit = np.polyfit(x,y,1, full=False)\n",
    "        x_plot = np.linspace(min(x), max(x), 1000)\n",
    "        plt.plot(x_plot, np.polyval(fit, x_plot), color='r', label=f'Linear Fit ($x$)')\n",
    "        plt.legend()\n",
    "        interpretation = f'As {column} increases by 1 unit, ROP changes by {round(fit[0],6)} ft/min'\n",
    "    elif 'quadratic' in fits.lower() or 'square' in fits.lower():\n",
    "        fit = np.polyfit(x,y,2, full=False)\n",
    "        plt.plot(x_plot, np.polyval(fit, x_plot), color='green', label=f'Quadratic Fit ($x^2$)')\n",
    "        plt.legend()\n",
    "        interpretation = None\n",
    "    elif 'cub' in fits.lower():\n",
    "        fit = np.polyfit(x,y,3, full=False)\n",
    "        plt.plot(x_plot, np.polyval(fit, x_plot), color='orange', label=f'Cubic Fit ($x^3$)')\n",
    "        plt.legend()\n",
    "        interpretation = None\n",
    "    else:\n",
    "        fit = None\n",
    "        interpretation = None\n",
    "    return fit, interpretation\n",
    "\n",
    "def density(data, x_column, y_column, bins=(20,20), cmin=None, cmax=None):\n",
    "    x = data[x_column]\n",
    "    y = data[y_column]\n",
    "    plt.hist2d(x, y, bins=(20,20), cmap=plt.cm.jet, cmin=cmin, cmax=cmax)\n",
    "    plt.xlabel(str(x_column))\n",
    "    plt.ylabel(str(y_column))\n",
    "    plt.title(f'Density Plot of {y_column} vs {x_column}')\n",
    "    plt.colorbar()\n",
    "    return None\n",
    "\n",
    "\n",
    "def plot_all(data, column):\n",
    "    for column in columns:\n",
    "        x = column\n",
    "        y = 'ROP (ft/min)'\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(1,2,1)\n",
    "\n",
    "        # Scatterplots\n",
    "        plt.scatter(data[x],data[y])\n",
    "        plt.title(f'{x} vs {y}')\n",
    "        plt.xlabel(str(x))\n",
    "        plt.ylabel(str(y))\n",
    "        # plt.show()\n",
    "\n",
    "        plt.subplot(1,2,2)     \n",
    "        plt.hist2d(data[x], data[y], bins=(20,20), cmap=plt.cm.jet)\n",
    "        plt.title(f'{x} vs {y}')\n",
    "        plt.xlabel(str(x))\n",
    "        plt.ylabel(str(y))\n",
    "        plt.show()\n",
    "\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdAbJxG0bjOr"
   },
   "source": [
    "### Make Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zs3MVX3YbpZf",
    "outputId": "fe599eec-8188-43ac-a423-7feddcef15bb"
   },
   "outputs": [],
   "source": [
    "# Print out the available columns to plot\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "G8D2pFjzX-LU",
    "outputId": "2935eb00-08da-4424-dd6b-955d3b1d93da"
   },
   "outputs": [],
   "source": [
    "sample = data.sample(1000)\n",
    "col = 'Rotation Speed Max (rpm)' # Change this value to plot different variables\n",
    "scatterplot(sample, col, 'ROP (ft/min)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "NtbzMvhhYQrV",
    "outputId": "a9597056-167a-4479-c361-e8ae6b0dca5d"
   },
   "outputs": [],
   "source": [
    "density(sample, x_column=col, y_column='ROP (ft/min)', bins=(20,20), cmin=None, cmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5nyvHbo9YTLS",
    "outputId": "2c4a7101-bede-43f0-f903-857b1bd6acf1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot all columns (except for one at a time)\n",
    "columns = ['RodCount','Rotation Speed Max (rpm)',\n",
    "                             'Rotation Torque Max (ft-lb)', 'Thrust Force Max (lbf)', \n",
    "                             'Mud Flow Rate Avg (gpm)', 'Mud Pressure Max (psi)',\n",
    "                             'Pull Force Maximum (lbf)', 'Pull Speed Average (ft/min)', \n",
    "                             'Drill String Length (ft)',]\n",
    "plot_all(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QIxP5UyUfWen",
    "outputId": "e46f8808-7133-43f3-c6cf-803a2c954b2d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(data.corr(), cmap='coolwarm', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POHANe2BXIOr"
   },
   "outputs": [],
   "source": [
    "# smaller_sample = data.sample(300)\n",
    "# profile = ProfileReport(smaller_sample)\n",
    "# try:\n",
    "#    profile.to_notebook_iframe()         # view as widget in Notebook\n",
    "# except:\n",
    "#    profile.to_file('data.html') # save as html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "jetVpP7QiNXj",
    "outputId": "9a7b2bd8-350a-4edd-f208-e0947db2cf44"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data['Model'], data['ROP (ft/min)'], orient='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFeBXEWsi-6H"
   },
   "source": [
    "## Step 5: Extracting Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we visualize the data we can make qualitative assessments of the data. However, qualitative observations often need to be backed by quantitative analysis. So how can we extract insights from our data in a concrete way?\n",
    "\n",
    "The first way to is to use summary statistics. The next cell shows a simple pandas function that gives summary statistics for the entire dataset. What do you notice? The second cell gives summary statistics for those rows whose ROP is in the top 25% (top quartile). How do they differ? Could you infer some of the reasons they may differ?\n",
    "\n",
    "The second way is to fit functions to your data. In this example, you can use a linear fit and use the coefficient to understand the effect that a unit change in x can have on y. Try different variables to see which variables show stronger correlations with ROP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "S1z7pnUtlBim",
    "outputId": "306aa4f4-def2-4799-a6bf-f1c149ef38e8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the data like when ROP is in the top 25%?\n",
    "# TODO: Describe the data with rows where ROP is in the top 25%\n",
    "#  - hint: column.quantile(0.75)\n",
    "#  - hint: new_data = data[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does each model perform?\n",
    "# TODO: Find out the mean values for each column GROUPED BY (hint) the Model type\n",
    "\n",
    "# grouping by Id  --  we deleted this but could this be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Dr_fscJUjH5C",
    "outputId": "6d903384-b7ea-4fe0-af00-03af29cee0b6"
   },
   "outputs": [],
   "source": [
    "# How does Drill String Length affect ROP?\n",
    "column = 'Rotation Torque Max (ft-lb)'\n",
    "fit, interpretation = scatterplot(data, column, 'ROP (ft/min)', fits='linear')\n",
    "plt.show()\n",
    "print(interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6F5c83xjIUt"
   },
   "source": [
    "## Step 6: DrillGIS\n",
    "\n",
    "Now we will look at an example of a dashboard, or a tool to view and analyze data that is generally hosted online. Click the link below and click around the website. The website shows fake drilling data that can be used to compare your drilling performance with those around you. You can also log into the website with code 571167 as a manager and 563624 as an operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQGPQn2Xjxve"
   },
   "source": [
    "[https://drillgis.com](https://drillgis.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhLQPTlQjMxO"
   },
   "source": [
    "## Step 7: Feature Engineering\n",
    "\n",
    "The following cells show some things you can do to try and prepare the features in your dataset for a Machine Learning model. These include one-hot encoding, scaling, and other processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQ2Il8GPnM_n"
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded = encoder.fit_transform(data[['Model']])\n",
    "for i, model in enumerate(encoder.categories_[0]):\n",
    "    data[model] = encoded[:,i]\n",
    "\n",
    "data = data.drop(columns=['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Md7T-_IoCI0S",
    "outputId": "36f616de-5795-4a96-eeba-e58b78682fb9"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxUY3WOAjXQU"
   },
   "outputs": [],
   "source": [
    "columns = data.columns\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data))\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "DP2lRxIwC6Li",
    "outputId": "b0810959-ee1e-4a38-f1d0-6b12dde755a8"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7N4zV7m2jneB"
   },
   "source": [
    "## Step 8: ML Data Processing\n",
    "The next steps are necessary for the analysis of the ML algorithms. First, we identify which data columns are the features and target. Then we split the data according to a train (80%) and a test (20%) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbQN-D2ojs4N"
   },
   "outputs": [],
   "source": [
    "# TODO: Assign X to the feature columns (variables) and y to the target (what we're predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcyZr0aNEb0E"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(# TODO: Fill in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wn7Qll-TjtLG"
   },
   "source": [
    "## Step 9: ML Implementation\n",
    "Now we will train and deploy a very simple ML model. How did it do? What other metrics could you use to measure your performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Rrdl9ZEQVJs"
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor()\n",
    "# TODO: Fit the model and make predictions on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UI7DAM6TDdlM",
    "outputId": "2c828a58-258f-4efc-e4ab-5cff6fc3fb0d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(# TODO: Fill in)\n",
    "mse = mean_squared_error(# TODO: Fill in)\n",
    "print(f'Mean Absolute Error (xp - x): {round(mae,6)}')\n",
    "print(f'Mean Squared Error (xp - x)^2: {round(mse,6)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying and Using a ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use pickle package to dump the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the file that you just dumped (loads in saved model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make sure the models are the same. How would you do that?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Engineering",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
